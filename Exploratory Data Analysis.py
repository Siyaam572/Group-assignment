# -*- coding: utf-8 -*-
"""EDA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/193G8LyReON5VLMz2_GkKY9aWoyn6lAMc

## **EXPLORATORY DATA ANALYSIS (EDA)**

# Import Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""# Import Dataset"""

from google.colab import drive
drive.mount('/content/gdrive')

"""## **Demand**"""

clean_demand=pd.read_csv('/content/gdrive/MyDrive/Advanced Data Analytics/Datasets/Cleaned Datasets/final_cleaned_demand.csv')

print(f"Shape: {clean_demand.shape}")
print(f"Columns: {clean_demand.columns.tolist()}")
display(clean_demand.head())

demand_features = [f'DF{i}' for i in range(1, 13)]  # DF1 to DF12
print("Demand Features:")
print(demand_features)
print(f"\nTotal: {len(demand_features)} features\n")

"""### Summary Statistics for Demand Features

"""

#summary statistics for all demand features
demand_summary_stats = clean_demand[demand_features].describe()

display(demand_summary_stats)

"""# **Distribution of Demand Features**"""

# Set up the figure and axes for a 3x4 grid of subplots
fig, axes = plt.subplots(3, 4, figsize=(18, 12))
axes = axes.flatten()

# Loop through each demand feature and plot its histogram
for i, feature in enumerate(demand_features):
    axes[i].hist(clean_demand[feature], bins=30, edgecolor='black', alpha=0.7)
    axes[i].set_title(f'Distribution of {feature}', fontsize=12)
    axes[i].set_xlabel('Value')
    axes[i].set_ylabel('Frequency')
    axes[i].grid(axis='y', alpha=0.75)

# Hide any unused subplots if demand_features is less than 12
for j in range(len(demand_features), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout() # Adjust layout to prevent overlapping titles
plt.suptitle('Histograms of Demand Features (DF1-DF12)', y=1.02, fontsize=16) # Overall title
plt.show()

"""**Correlation of Demand Features**"""

# Correlation Matrix for Demand Features
demand_correlation_matrix = clean_demand[demand_features].corr()

# Identify any pairs with high correlation (>0.7 or <-0.7)
high_correlation_pairs = []

for i in range(len(demand_correlation_matrix.columns)):
    for j in range(i + 1, len(demand_correlation_matrix.columns)):
        feature1 = demand_correlation_matrix.columns[i]
        feature2 = demand_correlation_matrix.columns[j]
        correlation_value = demand_correlation_matrix.iloc[i, j]

        if abs(correlation_value) > 0.7:
            high_correlation_pairs.append((feature1, feature2, correlation_value))

if high_correlation_pairs:
    print("\nHighly Correlated Demand Feature Pairs (absolute correlation > 0.7):")
    for f1, f2, corr_val in high_correlation_pairs:
        print(f"- {f1} and {f2}: {corr_val:.2f}")
else:
    print("\nNo highly correlated demand feature pairs (absolute correlation > 0.7) found.")


# Heatmap to visualize correlations
plt.figure(figsize=(10, 8))
sns.heatmap(demand_correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Correlation Matrix of Demand Features (DF1-DF12)', fontsize=16)
plt.show()

"""## Clean Plants"""

clean_plants=pd.read_csv('/content/gdrive/MyDrive/Advanced Data Analytics/Datasets/Cleaned Datasets/final_cleaned_plants.csv')

print(f"Shape: {clean_plants.shape}")
print(f"Columns: {clean_plants.columns.tolist()}")
display(clean_plants.head())

plant_features = [f'PF{i}' for i in range(1, 19)]   # PF1 to PF18
print("Plant Features:")
print(plant_features)
print(f"\nTotal: {len(plant_features)} features")

"""### Summary Statistics for Plant Features

"""

plant_summary_stats = clean_plants[plant_features].describe()
display(plant_summary_stats)

"""Distribution of Plant features"""

# figure and axes for a 3x6 grid of subplots for plant features
fig, axes = plt.subplots(3, 6, figsize=(24, 12)) # 3 rows, 6 columns
axes = axes.flatten() # Flatten the 2D array of axes for easy iteration

# Loop through each plant feature and plot its histogram
for i, feature in enumerate(plant_features):
    axes[i].hist(clean_plants[feature], bins=30, edgecolor='black', alpha=0.7)
    axes[i].set_title(f'Distribution of {feature}', fontsize=12)
    axes[i].set_xlabel('Value')
    axes[i].set_ylabel('Frequency')
    axes[i].grid(axis='y', alpha=0.75)

# Hide any unused subplots if plant_features is less than 18
for j in range(len(plant_features), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout() # Adjust layout to prevent overlapping titles
plt.suptitle('Histograms of Plant Features (PF1-PF18)', y=1.02, fontsize=16) # Overall title
plt.show()

"""Clean Generation Costs"""

clean_costs=pd.read_csv('/content/gdrive/MyDrive/Advanced Data Analytics/Datasets/Cleaned Datasets/final_cleaned_generation_costs.csv')

print(f"Shape: {clean_costs.shape}")
print(f"Columns: {clean_costs.columns.tolist()}")
display(clean_costs.head())

"""### Summary Statistics for Generation Costs"""

costs_summary_stats = clean_costs['Cost_USD_per_MWh'].describe()
display(costs_summary_stats)

# histogram for distribution of generation cost
plt.figure(figsize=(10, 6))
plt.hist(clean_costs['Cost_USD_per_MWh'], bins=50, edgecolor='black', alpha=0.7)
plt.title('Distribution of Generation Cost (Cost_USD_per_MWh)', fontsize=16)
plt.xlabel('Cost (USD per MWh)')
plt.ylabel('Frequency')
plt.grid(axis='y', alpha=0.75)
plt.show()

# Count demands per region
region_counts = clean_demand['DF_region'].value_counts()
print("\nDemand Counts by Region:")
display(region_counts)

# Count demands per day type
daytype_counts = clean_demand['DF_daytype'].value_counts()
print("\nDemand Counts by Day Type:")
display(daytype_counts)

# visualization
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1) # 1 row, 2 columns, 1st plot
sns.barplot(x=region_counts.index, y=region_counts.values, hue=region_counts.index, palette='viridis', legend=False)
plt.title('Demand Counts by Region', fontsize=14)
plt.xlabel('Region')
plt.ylabel('Number of Demands')
plt.grid(axis='y', alpha=0.75)

plt.subplot(1, 2, 2) # 1 row, 2 columns, 2nd plot
sns.barplot(x=daytype_counts.index, y=daytype_counts.values, hue=daytype_counts.index, palette='plasma', legend=False)
plt.title('Demand Counts by Day Type', fontsize=14)
plt.xlabel('Day Type')
plt.ylabel('Number of Demands')
plt.grid(axis='y', alpha=0.75)

plt.tight_layout()
plt.show()

"""###Outlier Analysis"""

# Initialize a dictionary to store outlier counts for each feature
outlier_counts = {}

print("Outlier Detection for Demand Features (IQR Method):")

# Loop through each demand feature
for feature in demand_features:
    # Calculate Q1 (25th percentile) and Q3 (75th percentile)
    Q1 = clean_demand[feature].quantile(0.25)
    Q3 = clean_demand[feature].quantile(0.75)

    # Calculate the Interquartile Range (IQR)
    IQR = Q3 - Q1

    # Define outlier bounds
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Count outliers (values outside the bounds)
    num_outliers = clean_demand[(clean_demand[feature] < lower_bound) | (clean_demand[feature] > upper_bound)].shape[0]

    outlier_counts[feature] = num_outliers
    print(f"- {feature}: {num_outliers} outliers")

"""# **Merge datasets**"""

# Step 1: Merge clean_demand with clean_costs on 'Demand ID'
demand_costs = pd.merge(clean_demand, clean_costs, on='Demand ID', how='inner')
print(f"Shape of merged demand_costs dataframe: {demand_costs.shape}")
print(f"Columns of merged demand_costs dataframe: {demand_costs.columns.tolist()}")
display(demand_costs.head())

"""## Step 2: Merging demand_costs with clean_plants

"""

# Step 2: Merge demand_costs with clean_plants on 'Plant ID'
final_merged_df = pd.merge(demand_costs, clean_plants, on='Plant ID', how='inner')
print(f"Shape of final_merged_df dataframe: {final_merged_df.shape}")
print(f"Columns of final_merged_df dataframe: {final_merged_df.columns.tolist()}")
display(final_merged_df.head())

"""Column rearrangement"""

# Get the current list of columns
current_columns = final_merged_df.columns.tolist()

new_column_order = ['Demand ID', 'Plant ID']  # Create the new desired order starting with 'Demand ID', then 'Plant ID'

for col in current_columns:
    if col not in ['Demand ID', 'Plant ID']:   # Add the remaining columns, excluding 'Demand ID' and 'Plant ID' from their original positions
        new_column_order.append(col)

final_merged_df = final_merged_df[new_column_order] # Apply the new column order to the DataFrame

print(f"Shape of final_merged_df after reordering: {final_merged_df.shape}")
print(f"Columns of final_merged_df after reordering: {final_merged_df.columns.tolist()}")

"""##Costs by plant type"""

# Group by plant type and calculate average cost
avg_cost_by_plant_type = final_merged_df.groupby('Plant Type')['Cost_USD_per_MWh'].mean().sort_values(ascending=True)

print("\nAverage Cost (USD/MWh) by Plant Type:")
display(avg_cost_by_plant_type)

#figure for two plots
fig, axes = plt.subplots(1, 2, figsize=(18, 6))

#bar chart for average costs
sns.barplot(x=avg_cost_by_plant_type.values, y=avg_cost_by_plant_type.index, palette='viridis', ax=axes[0], hue=avg_cost_by_plant_type.index, legend=False)
axes[0].set_title('Average Cost (USD/MWh) by Plant Type', fontsize=14)
axes[0].set_xlabel('Average Cost (USD/MWh)')
axes[0].set_ylabel('Plant Type')
axes[0].grid(axis='x', alpha=0.75)

#boxplot showing cost distribution by plant type
sns.boxplot(x='Cost_USD_per_MWh', y='Plant Type', data=final_merged_df, ax=axes[1], palette='viridis', order=avg_cost_by_plant_type.index, hue='Plant Type', legend=False)
axes[1].set_title('Cost Distribution (USD/MWh) by Plant Type', fontsize=14)
axes[1].set_xlabel('Cost (USD/MWh)')
axes[1].set_ylabel('Plant Type')
axes[1].grid(axis='x', alpha=0.75)

plt.tight_layout()
plt.show()

"""##Region Matching Analysis"""

# Create new column: 'Same_Region' (True if demand region == plant region)
final_merged_df['Same_Region'] = (final_merged_df['DF_region'] == final_merged_df['Region'])

print("First few rows with 'Same_Region' column:")
display(final_merged_df[['Demand ID', 'Plant ID', 'DF_region', 'Region', 'Same_Region', 'Cost_USD_per_MWh']].head())

# Compare average costs for Same_Region vs Different_Region
avg_costs_by_region_match = final_merged_df.groupby('Same_Region')['Cost_USD_per_MWh'].mean()

print("\nAverage Cost (USD/MWh) by Regional Match:")
display(avg_costs_by_region_match)

# Calculate the difference in average cost
diff_cost = avg_costs_by_region_match.loc[True] - avg_costs_by_region_match.loc[False]
print(f"\nDifference in average cost (Same Region - Different Region): {diff_cost:.2f} USD/MWh")

"""##Cost by Day Type Analysis"""

#group by day type and calculate average cost
avg_cost_by_daytype = final_merged_df.groupby('DF_daytype')['Cost_USD_per_MWh'].mean().sort_values(ascending=False)

print("\nAverage Cost (USD/MWh) by Day Type:")
display(avg_cost_by_daytype)

"""##Best Combinations

Which plant type works best for each region?
"""

# Group by Demand Region and Plant Type to calculate average cost
regional_plant_costs = final_merged_df.groupby(['DF_region', 'Plant Type'])['Cost_USD_per_MWh'].mean().reset_index()

# Find the lowest and highest average cost plant type for each region
best_worst_plants_per_region = []

for region in regional_plant_costs['DF_region'].unique():
    region_data = regional_plant_costs[regional_plant_costs['DF_region'] == region]

    # Lowest cost plant
    lowest_cost_plant = region_data.loc[region_data['Cost_USD_per_MWh'].idxmin()]

    # Highest cost plant
    highest_cost_plant = region_data.loc[region_data['Cost_USD_per_MWh'].idxmax()]

    best_worst_plants_per_region.append({
        'Demand Region': region,
        'Lowest Cost Plant Type': lowest_cost_plant['Plant Type'],
        'Lowest Avg Cost (USD/MWh)': lowest_cost_plant['Cost_USD_per_MWh'],
        'Highest Cost Plant Type': highest_cost_plant['Plant Type'],
        'Highest Avg Cost (USD/MWh)': highest_cost_plant['Cost_USD_per_MWh']
    })

# Convert results to a DataFrame for display
summary_table_best_worst = pd.DataFrame(best_worst_plants_per_region)

print("\nSummary of Best and Worst Plant Types by Demand Region (by average cost):")
display(summary_table_best_worst)

"""## Baseline Performance

To demonstrate that a simple approach of always picking one plant is suboptimal, thereby motivating the need for machine learning or more sophisticated optimization.
"""

# For each Demand ID, find the Plant ID that offers the minimum Cost_USD_per_MWh
optimal_costs = final_merged_df.loc[final_merged_df.groupby('Demand ID')['Cost_USD_per_MWh'].idxmin()]

# Keep only the relevant columns for optimal solution
optimal_costs = optimal_costs[['Demand ID', 'Plant ID', 'Cost_USD_per_MWh']].rename(columns={
    'Plant ID': 'Optimal Plant ID',
    'Cost_USD_per_MWh': 'Optimal Cost_USD_per_MWh'
})

display(optimal_costs.head())

print(f"\nShape of optimal_costs DataFrame: {optimal_costs.shape}")
print(f"Average Optimal Cost: {optimal_costs['Optimal Cost_USD_per_MWh'].mean():.2f} USD/MWh")

"""##Baseline RSME for each plants"""

plant_rmse_results = []  # List to store RMSE for each plant

unique_plant_ids = final_merged_df['Plant ID'].unique()  # Get all unique Plant IDs
print(f"Unique Plant IDs: {unique_plant_ids.tolist()}")
print(f"Total unique plants: {len(unique_plant_ids)}")

final_merged_df = pd.merge(final_merged_df, optimal_costs[['Demand ID', 'Optimal Cost_USD_per_MWh']], on='Demand ID', how='left')
final_merged_df['Cost_Error_vs_Optimal'] = final_merged_df['Optimal Cost_USD_per_MWh'] - final_merged_df['Cost_USD_per_MWh']
display(final_merged_df[['Demand ID', 'Plant ID', 'Cost_USD_per_MWh', 'Optimal Cost_USD_per_MWh', 'Cost_Error_vs_Optimal']].head())

# Iterate through each plant to calculate its baseline RMSE
for plant_id in unique_plant_ids:
    # Filter the merged DataFrame for the current plant, assuming it is the 'chosen plant' for all demands
    current_plant_data = final_merged_df[final_merged_df['Plant ID'] == plant_id]

    # The 'Error(d)' for this plant is its 'Cost_Error_vs_Optimal'
    errors = current_plant_data['Cost_Error_vs_Optimal']

    # Calculate RMSE (Score) as defined in the brief: sqrt( (1/D) * sum(Error(d)^2) )
    rmse = np.sqrt(np.mean(errors**2))

    plant_rmse_results.append({'Plant ID': plant_id, 'RMSE': rmse})

# Convert results to a DataFrame and sort by RMSE
baseline_plant_rmse_df = pd.DataFrame(plant_rmse_results)
baseline_plant_rmse_df = baseline_plant_rmse_df.sort_values(by='RMSE', ascending=True).reset_index(drop=True)

print("\nBaseline RMSE for Each Plant (sorted by RMSE, lowest first):\n")
display(baseline_plant_rmse_df.head())

print("\nBaseline RMSE for Each Plant (sorted by RMSE, highest first):\n")
display(baseline_plant_rmse_df.tail())

# Identify the plant with the lowest RMSE
best_baseline_plant_id = baseline_plant_rmse_df.iloc[0]['Plant ID']
best_baseline_plant_rmse = baseline_plant_rmse_df.iloc[0]['RMSE']

print(f"The plant with the LOWEST RMSE is {best_baseline_plant_id} with an RMSE of {best_baseline_plant_rmse:.2f} USD/MWh.")

# Verify P28 baseline is correct
print("\n=== P28 BASELINE VERIFICATION ===")
p28_data = final_merged_df[final_merged_df['Plant ID'] == 'P28']
print(f"Number of demands with P28: {len(p28_data)}")

p28_errors = p28_data['Cost_Error_vs_Optimal'].values
print(f"P28 errors (first 10): {p28_errors[:10]}")
print(f"Mean error: {p28_errors.mean():.2f}")
print(f"Min error: {p28_errors.min():.2f}")
print(f"Max error: {p28_errors.max():.2f}")
print(f"Number of zero errors (optimal): {(p28_errors == 0).sum()}")
print(f"RMSE: {np.sqrt(np.mean(p28_errors**2)):.2f}")

# Identify the plant with the highest RMSE
worst_baseline_plant_id = baseline_plant_rmse_df.iloc[-1]['Plant ID']
worst_baseline_plant_rmse = baseline_plant_rmse_df.iloc[-1]['RMSE']

print(f"The plant with the HIGHEST RMSE is {worst_baseline_plant_id} with an RMSE of {worst_baseline_plant_rmse:.2f} USD/MWh.")

#Identify the plant with the lowest RMSE
best_baseline_plant_id = baseline_plant_rmse_df.iloc[0]['Plant ID']
best_baseline_plant_rmse = baseline_plant_rmse_df.iloc[0]['RMSE']

print(f"The plant with the LOWEST RMSE is {best_baseline_plant_id} with an RMSE of {best_baseline_plant_rmse:.2f} USD/MWh.")

# in how many scenarios this plant is actually optimal

best_plant_scenarios = final_merged_df[final_merged_df['Plant ID'] == best_baseline_plant_id] # filter final_merged_df for the best_baseline_plant_id

num_optimal_scenarios = best_plant_scenarios[best_plant_scenarios['Cost_Error_vs_Optimal'] == 0].shape[0] # how many of these scenarios have an error of 0

total_scenarios = final_merged_df['Demand ID'].nunique()  # The total number of demand scenarios is the number of unique Demand IDs
percentage_optimal = (num_optimal_scenarios / total_scenarios) * 100

print(f"{best_baseline_plant_id} is actually optimal in {num_optimal_scenarios}/{total_scenarios} scenarios ({percentage_optimal:.1f}%).")

# Visualizations for Error Distribution

# 1. Histogram of Cost Error vs. Optimal Cost
# This shows the overall distribution of how much more expensive a chosen plant is compared to the optimal plant for any given demand.
plt.figure(figsize=(10, 6))
sns.histplot(final_merged_df['Cost_Error_vs_Optimal'], bins=50, kde=True, color='skyblue')
plt.title('Distribution of Cost Error vs. Optimal Cost', fontsize=16)
plt.xlabel('Cost Error (Optimal Cost - Actual Cost) (USD/MWh)', fontsize=12)
plt.ylabel('Frequency', fontsize=12)
plt.grid(axis='y', alpha=0.75)
plt.show()

# 2. Box Plot of Cost Error vs. Optimal Cost by Plant Type
# This helps identify if certain plant types consistently incur higher or lower errors when not perfectly optimal.
plt.figure(figsize=(12, 8))
sns.boxplot(x='Cost_Error_vs_Optimal', y='Plant Type', data=final_merged_df, palette='viridis', hue='Plant Type', legend=False)
plt.title('Distribution of Cost Error vs. Optimal Cost by Plant Type', fontsize=16)
plt.xlabel('Cost Error (Optimal Cost - Actual Cost) (USD/MWh)', fontsize=12)
plt.ylabel('Plant Type', fontsize=12)
plt.grid(axis='x', alpha=0.75)
plt.show()

# Chart 3: Baseline RMSE for Each Plant
# Shows RMSE if we always pick each specific plant for all demands

plt.figure(figsize=(14, 6))

# Sort by RMSE
baseline_sorted = baseline_plant_rmse_df.sort_values('RMSE')

# Create bar chart
plt.bar(range(len(baseline_sorted)), baseline_sorted['RMSE'], color='steelblue', alpha=0.7)
plt.axhline(y=baseline_sorted['RMSE'].median(), color='red', linestyle='--',
            linewidth=2, label=f"Median RMSE: ${baseline_sorted['RMSE'].median():.2f}")
plt.axhline(y=baseline_sorted['RMSE'].min(), color='green', linestyle='--',
            linewidth=2, label=f"Best RMSE (P28): ${baseline_sorted['RMSE'].min():.2f}")

plt.xlabel('Plant Rank (sorted by RMSE)', fontsize=12)
plt.ylabel('RMSE (USD/MWh)', fontsize=12)
plt.title('Baseline RMSE: If We Always Choose One Plant for All Demands', fontsize=16)
plt.legend(fontsize=11)
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()

print(f"Best baseline plant: {baseline_sorted.iloc[0]['Plant ID']} with RMSE = ${baseline_sorted.iloc[0]['RMSE']:.2f}")
print(f"Worst baseline plant: {baseline_sorted.iloc[-1]['Plant ID']} with RMSE = ${baseline_sorted.iloc[-1]['RMSE']:.2f}")
print(f"Median baseline RMSE: ${baseline_sorted['RMSE'].median():.2f}")

# Chart 4A: Error Distribution for Best Baseline Plant (P28)
# Shows how often P28 is close to optimal vs far from optimal

p28_errors = final_merged_df[final_merged_df['Plant ID'] == 'P28']['Cost_Error_vs_Optimal']

plt.figure(figsize=(12, 6))
plt.hist(p28_errors, bins=40, color='green', alpha=0.7, edgecolor='black')
plt.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Optimal (Error = 0)')
plt.axvline(x=p28_errors.mean(), color='blue', linestyle='--', linewidth=2,
            label=f'Mean Error: ${p28_errors.mean():.2f}')
plt.xlabel('Cost Error (USD/MWh)', fontsize=12)
plt.ylabel('Frequency', fontsize=12)
plt.title('Error Distribution for Best Baseline Plant (P28)\nIf P28 is Chosen for All 500 Demand Scenarios', fontsize=14)
plt.legend(fontsize=11)
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()

print(f"P28 Error Statistics:")
print(f"  Mean error: ${p28_errors.mean():.2f}")
print(f"  Median error: ${p28_errors.median():.2f}")
print(f"  Std deviation: ${p28_errors.std():.2f}")
print(f"  Min error (worst case): ${p28_errors.min():.2f}")
print(f"  Max error (best case): ${p28_errors.max():.2f}")

# Chart 4B: How Often is P28 Actually Optimal?
# Pie chart showing optimal vs suboptimal scenarios

p28_errors = final_merged_df[final_merged_df['Plant ID'] == 'P28']['Cost_Error_vs_Optimal']

# Count optimal vs suboptimal
optimal_count = (p28_errors == 0).sum()
suboptimal_count = (p28_errors < 0).sum()
total_scenarios = len(p28_errors)

plt.figure(figsize=(10, 8))

# Create pie chart
colors = ['#2ecc71', '#e74c3c']  # Green for optimal, red for suboptimal
sizes = [optimal_count, suboptimal_count]
labels = [f'Actually Optimal\n{optimal_count} scenarios',
          f'Suboptimal\n{suboptimal_count} scenarios']
explode = (0.05, 0)  # Slightly separate the optimal slice

wedges, texts, autotexts = plt.pie(sizes, labels=labels, colors=colors,
                                     autopct='%1.1f%%', startangle=90,
                                     explode=explode,
                                     textprops={'fontsize': 13, 'weight': 'bold'},
                                     wedgeprops={'edgecolor': 'white', 'linewidth': 2})

# Make percentage text white for better contrast
for autotext in autotexts:
    autotext.set_color('white')
    autotext.set_fontsize(14)

plt.title('Performance of Best Baseline Plant (P28)\nOut of 500 Demand Scenarios',
          fontsize=16, weight='bold', pad=20)

plt.tight_layout()
plt.show()


print("P28 Performance Summary")
print(f"Total scenarios: {total_scenarios}")
print(f"Actually optimal: {optimal_count} ({optimal_count/total_scenarios*100:.1f}%)")
print(f"Suboptimal: {suboptimal_count} ({suboptimal_count/total_scenarios*100:.1f}%)")
print(f"RMSE: ${baseline_plant_rmse_df[baseline_plant_rmse_df['Plant ID']=='P28']['RMSE'].values[0]:.2f}")