# -*- coding: utf-8 -*-
"""Model fitting for all datasets

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AyzkpPfg4lwVuqZ7pFXVVOLocv3CdZv9

# **MODEL FITTING AND COMPARISON, CROSS VALIDATION AND HYPERPARAMETER OPTIMIZATION**
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, LeaveOneGroupOut, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import (mean_squared_error, r2_score, make_scorer)

"""### Load Datasets"""

demand = pd.read_csv('/content/drive/MyDrive/Advanced Data Analytics/Datasets/Cleaned Datasets/final_cleaned_demand.csv')
plants = pd.read_csv('/content/drive/MyDrive/Advanced Data Analytics/Datasets/Cleaned Datasets/final_cleaned_plants.csv')
generation_costs = pd.read_csv('/content/drive/MyDrive/Advanced Data Analytics/Datasets/Cleaned Datasets/final_cleaned_generation_costs.csv')

"""## Merge Datasets"""

merged_df_1 = pd.merge(generation_costs, demand, on='Demand ID', how='inner') #merge generation costs and demand on Demand ID
final_merged_df = pd.merge(merged_df_1, plants, on='Plant ID', how='inner') #Merge results with plants on plant ID

print("Shape of merged_df_1:", merged_df_1.shape)
print("Shape of final_merged_df:", final_merged_df.shape)
print("First 5 rows of final_merged_df:")
display(final_merged_df.head())

"""## Prepare Data for Model
Split the combined dataset into X (features), y (target: Cost_USD_per_MWh), and Groups (Demand ID), and apply one-hot encoding to categorical features.

"""

y = final_merged_df['Cost_USD_per_MWh'] #extract target variable y
groups = final_merged_df['Demand ID'] #create groups using Demand ID

print("Shape of y:", y.shape)
print("Shape of groups:", groups.shape)
print("\nFirst 5 values of y:")
print(y.head())
print("\nFirst 5 values of groups:")
print(groups.head())

X = final_merged_df.drop(columns=['Cost_USD_per_MWh', 'Demand ID', 'Plant ID']) #droping target value(cost) and Demand and Plant ID from the merged dataframe
categorical_cols = X.select_dtypes(include='object').columns # Identify categorical columns

# Apply one-hot encoding on categorical columns
X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)

print("Shape of X:", X.shape)
print("\nFirst 5 rows of X:")
print(X.head())

"""## Train/Test Split

"""

unique_demand_ids = groups.unique()  #Total number of unique demand IDs from the groups
print("Total number of unique Demand ID values:", len(unique_demand_ids))

np.random.seed(42) # for reproducibility
test_demand_ids = np.random.choice(unique_demand_ids, 20, replace=False) #randomly chose 20 unique demand IDs
train_demand_ids = np.setdiff1d(unique_demand_ids, test_demand_ids)

print("Number of Demand IDs in test set:", len(test_demand_ids))
print("Number of Demand IDs in train set:", len(train_demand_ids))
print("Test Demand IDs (first 5):", test_demand_ids[:5])
print("Train Demand IDs (first 5):", train_demand_ids[:5])

X_train = X[groups.isin(train_demand_ids)] #x corresponding to demain ID for train
y_train = y[groups.isin(train_demand_ids)] #y corresponding to demand ID for train
X_test = X[groups.isin(test_demand_ids)]
y_test = y[groups.isin(test_demand_ids)]

print("Shape of X_train:", X_train.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_test:", y_test.shape)

print("\nFirst 5 rows of X_train:")
print(X_train.head())
print("\nFirst 5 values of y_train:")
print(y_train.head())

"""## Train Regression Model 1: RandomForestRegressor"""

model = RandomForestRegressor(random_state=42) #instantiate Model RandomForestRegressor
model.fit(X_train, y_train)
print("RandomForestRegressor model trained successfully.")

y_pred = model.predict(X_test) #make predictions on x test

mse = mean_squared_error(y_test, y_pred)
model_r2_score = model.score(X_test, y_test) #evaluate the model performance

print(f"R-squared on test set: {model_r2_score:.4f}")
print(f"Mean Squared Error on test set: {mse:.4f}")

# Score the training set
y_train_pred = model.predict(X_train)
mse_train = mean_squared_error(y_train, y_train_pred)
r2_train_score = model.score(X_train, y_train)

print(f"\nR-squared on training set: {r2_train_score:.4f}")
print(f"Mean Squared Error on training set: {mse_train:.4f}")

"""Calculate Custom RSME"""

#custom error calculation
test_data_for_error = final_merged_df.loc[X_test.index, ['Demand ID', 'Plant ID', 'Cost_USD_per_MWh']].copy() #extracting the demand, plant ID and actual cost of the test set based on their index
test_data_for_error['Predicted_Cost_USD_per_MWh'] = y_pred #adding predicted costs

print("Shape of test_data_for_error:", test_data_for_error.shape)
print("\nFirst 5 rows of test_data_for_error:")
print(test_data_for_error.head())

"""**Calculate Individual Demand Errors (Eq. 1)**

"""

#Iterate through each unique Demand ID in test set, extract necessary costs and compute the error
demand_errors = [] #initialize empty list to store calculated error d for each unique demand ID in test set

for demand_id in test_demand_ids:
    current_demand_df = test_data_for_error[test_data_for_error['Demand ID'] == demand_id]
    ml_selected_plant_row = current_demand_df.loc[current_demand_df['Predicted_Cost_USD_per_MWh'].idxmin()]  #Find the row where 'Predicted_Cost_USD_per_MWh' is at its minimum (ML-selected plant)
    ml_selected_actual_cost = ml_selected_plant_row['Cost_USD_per_MWh'] #Extract the 'Cost_USD_per_MWh' (actual cost) from this ML-selected plant's row
    optimal_actual_cost = current_demand_df['Cost_USD_per_MWh'].min() #Find the minimum 'Cost_USD_per_MWh' (actual cost) among all plants for this demand_id (Optimal_cost)
    error_d = optimal_actual_cost - ml_selected_actual_cost #Calculate the error for this demand
    demand_errors.append(error_d) #Append error_d to the demand_errors list

print("Calculated Demand Errors (Error(d) = Optimal_cost - ML_selected_cost):")
print(demand_errors[:10])
print(f"Total number of demand errors calculated: {len(demand_errors)}")

#calculate custom RSME using eqn 2 formula
D = len(demand_errors)
sum_of_squared_errors = sum([e**2 for e in demand_errors])
custom_rmse_score = np.sqrt((1/D) * sum_of_squared_errors)
print(f"Custom RMSE Score: {custom_rmse_score:.4f}")

"""RFR: Feature importance"""

#feature importance
feature_importances = pd.Series(model.feature_importances_, index=X.columns)
sorted_feature_importances = feature_importances.sort_values(ascending=False)

print("Top 15 Feature Importances:")
print(sorted_feature_importances.head(15))

#visualize feature importance
plt.figure(figsize=(12, 8))
sns.barplot(x=sorted_feature_importances.head(15).values, y=sorted_feature_importances.head(15).index)
plt.title('Top 15 Feature Importances for RandomForestRegressor')
plt.xlabel('Feature Importance Score')
plt.ylabel('Feature Name')
plt.tight_layout()
plt.show()

"""## Training Regression Model 2: GradientBoostingRegressor(GBR)"""

gbr_model = GradientBoostingRegressor(random_state=42)
gbr_model.fit(X_train, y_train)
print("GradientBoostingRegressor model trained successfully.")

y_pred_gbr = gbr_model.predict(X_test)
mse_gbr = mean_squared_error(y_test, y_pred_gbr)
model_r2_score_gbr = gbr_model.score(X_test, y_test)

print(f"R-squared on test set (GradientBoostingRegressor): {model_r2_score_gbr:.4f}")
print(f"Mean Squared Error on test set (GradientBoostingRegressor): {mse_gbr:.4f}")

# Score the training set for GradientBoostingRegressor
y_train_pred_gbr = gbr_model.predict(X_train)
mse_train_gbr = mean_squared_error(y_train, y_train_pred_gbr)
r2_train_score_gbr = gbr_model.score(X_train, y_train)

print(f"\nR-squared on training set (GradientBoostingRegressor): {r2_train_score_gbr:.4f}")
print(f"Mean Squared Error on training set (GradientBoostingRegressor): {mse_train_gbr:.4f}")

"""GBR: Calculate custom RSME


"""

test_data_for_error_gbr= final_merged_df.loc[X_test.index, ['Demand ID', 'Plant ID', 'Cost_USD_per_MWh']].copy()
test_data_for_error_gbr['Predicted_Cost_USD_per_MWh'] = y_pred_gbr

print("Shape of test_data_for_error_gbr:", test_data_for_error_gbr.shape)
print("\nFirst 5 rows of test_data_for_error_gbr:")
print(test_data_for_error_gbr.head())

gbr_demand_errors = []

for demand_id in test_demand_ids:
    current_demand_df_gbr = test_data_for_error_gbr[test_data_for_error_gbr['Demand ID'] == demand_id]

    # Find the row where 'Predicted_Cost_USD_per_MWh' is at its minimum (ML-selected plant by GBR)
    ml_selected_plant_row_gbr = current_demand_df_gbr.loc[current_demand_df_gbr['Predicted_Cost_USD_per_MWh'].idxmin()]

    #Extract the 'Cost_USD_per_MWh' (actual cost) from this ML-selected plant's row
    ml_selected_actual_cost_gbr = ml_selected_plant_row_gbr['Cost_USD_per_MWh']

    #Find the minimum 'Cost_USD_per_MWh' (actual cost) among all plants for this demand_id (Optimal_cost)
    optimal_actual_cost_gbr = current_demand_df_gbr['Cost_USD_per_MWh'].min()

    #Calculate the error for this demand
    error_d_gbr = optimal_actual_cost_gbr - ml_selected_actual_cost_gbr

    #Append error_d to the gbr_demand_errors list
    gbr_demand_errors.append(error_d_gbr)

print("Calculated Demand Errors for GradientBoostingRegressor (Error(d) = Optimal_cost - ML_selected_cost):")
print(gbr_demand_errors[:10]) # Print first 10 errors for inspection
print(f"Total number of demand errors calculated for GBR: {len(gbr_demand_errors)}")

#RSME score eqn 2
D_gbr = len(gbr_demand_errors)
sum_of_squared_errors_gbr = sum([e**2 for e in gbr_demand_errors])
custom_rmse_score_gbr = np.sqrt((1/D_gbr) * sum_of_squared_errors_gbr)

print(f"Custom RMSE Score for GradientBoostingRegressor: {custom_rmse_score_gbr:.4f}")

"""GBR: Feature Importance"""

#feature importance
gbr_feature_importances = pd.Series(gbr_model.feature_importances_, index=X.columns)
sorted_gbr_feature_importances = gbr_feature_importances.sort_values(ascending=False)

print("Top 15 Feature Importances for GradientBoostingRegressor:")
print(sorted_gbr_feature_importances.head(15))

#visualize feature importance
plt.figure(figsize=(12, 8))
sns.barplot(x=sorted_gbr_feature_importances.head(15).values, y=sorted_gbr_feature_importances.head(15).index)
plt.title('Top 15 Feature Importances for GradientBoostingRegressor')
plt.xlabel('Feature Importance Score')
plt.ylabel('Feature Name')
plt.tight_layout()
plt.show()

# After calculating RF custom RMSE

print("RANDOMFOREST ML MODEL VERIFICATION (on test set)")

print(f"\nNumber of test demands: {len(test_demand_ids)}")
print(f"Number of errors calculated: {len(demand_errors)}")

print(f"\nRF model errors for test demands (first 10): {demand_errors[:10]}")
print(f"Mean error: {np.mean(demand_errors):.2f}")
print(f"Min error: {min(demand_errors):.2f}")
print(f"Max error: {max(demand_errors):.2f}")
print(f"Std dev of errors: {np.std(demand_errors):.2f}")
print(f"Number of zero errors (ML selected optimal): {sum([1 for e in demand_errors if e == 0])}")

print(f"\nRandomForest RMSE: {custom_rmse_score:.2f}")
print(f"Baseline (P28) RMSE: 8.74")
print(f"Improvement: {((8.74 - custom_rmse_score) / 8.74 * 100):.1f}%")

if custom_rmse_score < 8.74:
    print(" RandomForest beats baseline")
else:
    print("RandomForest worse than baseline")



print("GRADIENTBOOSTING ML MODEL VERIFICATION (on test set)")


print(f"\nNumber of test demands: {len(test_demand_ids)}")
print(f"Number of errors calculated: {len(gbr_demand_errors)}")

print(f"\nGB model errors for test demands (first 10): {gbr_demand_errors[:10]}")
print(f"Mean error: {np.mean(gbr_demand_errors):.2f}")
print(f"Min error: {min(gbr_demand_errors):.2f}")
print(f"Max error: {max(gbr_demand_errors):.2f}")
print(f"Std dev of errors: {np.std(gbr_demand_errors):.2f}")
print(f"Number of zero errors (ML selected optimal): {sum([1 for e in gbr_demand_errors if e == 0])}")

print(f"\nGradientBoosting RMSE: {custom_rmse_score_gbr:.2f}")
print(f"Baseline (P28) RMSE: 8.74")
print(f"Improvement: {((8.74 - custom_rmse_score_gbr) / 8.74 * 100):.1f}%")

if custom_rmse_score_gbr < 8.74:
    print("GradientBoosting beats baseline")
else:
    print("GradientBoosting worse than baseline")

"""**CROSS VALIDATION**

### For GradientBoostingRegressor Model
Phase 1: Sample CV using 20 demands
"""

np.random.seed(42) # for reproducibility
sample_demand_ids = np.random.choice(unique_demand_ids, 20, replace=False)

print("Number of Demand IDs in sample set:", len(sample_demand_ids))
print("Sample Demand IDs (first 5):", sample_demand_ids[:5])

#create x_sample,y_sample and groups_sample df to contain data corresponding to only the newly selected Demand IDs
X_sample = X[groups.isin(sample_demand_ids)]
y_sample = y[groups.isin(sample_demand_ids)]
groups_sample = groups[groups.isin(sample_demand_ids)]

print("Shape of X_sample:", X_sample.shape)
print("Shape of y_sample:", y_sample.shape)
print("Shape of groups_sample:", groups_sample.shape)

print("\nFirst 5 rows of X_sample:")
print(X_sample.head())
print("\nFirst 5 values of y_sample:")
print(y_sample.head())
print("\nFirst 5 values of groups_sample:")
print(groups_sample.head())

"""Configure custom scorer"""

#LOGO CV on sample data for GBR Model

def custom_rmse_scorer(y_true_fold, y_pred_fold):

   # Get the original index for this fold
    fold_indices = y_true_fold.index

    # Reconstruct the necessary columns from the global final_merged_df using these indices
    fold_data = final_merged_df.loc[fold_indices, ['Demand ID', 'Plant ID']].copy()

    # Assign the true and predicted costs to this fold_data DataFrame
    fold_data['Cost_USD_per_MWh'] = y_true_fold
    fold_data['Predicted_Cost_USD_per_MWh'] = y_pred_fold

    demand_errors_fold = []
    unique_demand_ids_fold = fold_data['Demand ID'].unique()

    for demand_id in unique_demand_ids_fold:
        current_demand_df = fold_data[fold_data['Demand ID'] == demand_id]
        ml_selected_plant_row = current_demand_df.loc[current_demand_df['Predicted_Cost_USD_per_MWh'].idxmin()]  #Identify ML-selected plant (min predicted cost)
        ml_selected_actual_cost = ml_selected_plant_row['Cost_USD_per_MWh'] #Extract actual cost of ML-selected plant
        optimal_actual_cost = current_demand_df['Cost_USD_per_MWh'].min() #Find optimal actual cost for this demand_id
        error_d = optimal_actual_cost - ml_selected_actual_cost  #Calculate Error(d)
        demand_errors_fold.append(error_d)

    if len(demand_errors_fold) > 0:
        sum_of_squared_errors = sum([e**2 for e in demand_errors_fold])
        custom_rmse = np.sqrt((1 / len(demand_errors_fold)) * sum_of_squared_errors)
    else:
        custom_rmse = 0.0

    return -custom_rmse

# Wrap the function using make_scorer
custom_scorer = make_scorer(custom_rmse_scorer, greater_is_better=False)

print("Custom RMSE scorer 'custom_scorer' redefined and wrapped for cross-validation.")

cv_sample = LeaveOneGroupOut()
cv_scores_sample = cross_val_score(gbr_model, X_sample, y_sample, groups=groups_sample, cv=cv_sample, scoring=custom_scorer, n_jobs=1)

print("Cross-validation scores (negative custom RMSE) on sample data with n_jobs=1:")
print(cv_scores_sample)
print(f"Mean CV score on sample data: {cv_scores_sample.mean():.4f}")
print(f"Standard deviation of CV scores on sample data: {cv_scores_sample.std():.4f}")

overall_cv_rmse_sample = np.abs(cv_scores_sample.mean())
print(f"Overall Custom RMSE from cross-validation (GradientBoostingRegressor, Sample Data): {overall_cv_rmse_sample:.4f}")

"""### For RandomForestRegressor Model
Phase 1: Sample CV using 20 demands
"""

np.random.seed(42) # for reproducibility
sample_demand_ids_rf = np.random.choice(unique_demand_ids, 20, replace=False)

print("Number of Demand IDs in new sample set for RF:", len(sample_demand_ids_rf))
print("New Sample Demand IDs for RF (first 5):", sample_demand_ids_rf[:5])

X_sample_rf = X[groups.isin(sample_demand_ids_rf)]
y_sample_rf = y[groups.isin(sample_demand_ids_rf)]
groups_sample_rf = groups[groups.isin(sample_demand_ids_rf)]

print("Shape of X_sample_rf:", X_sample_rf.shape)
print("Shape of y_sample_rf:", y_sample_rf.shape)
print("Shape of groups_sample_rf:", groups_sample_rf.shape)

print("\nFirst 5 rows of X_sample_rf:")
print(X_sample_rf.head())
print("\nFirst 5 values of y_sample_rf:")
print(y_sample_rf.head())
print("\nFirst 5 values of groups_sample_rf:")
print(groups_sample_rf.head())

cv_rf_sample = LeaveOneGroupOut()
cv_scores_rf_sample = cross_val_score(model, X_sample_rf, y_sample_rf, groups=groups_sample_rf, cv=cv_rf_sample, scoring=custom_scorer, n_jobs=1)

print("Cross-validation scores (negative custom RMSE) for RandomForestRegressor on sample data:")
print(cv_scores_rf_sample)
print(f"Mean CV score for RandomForestRegressor on sample data: {cv_scores_rf_sample.mean():.4f}")
print(f"Standard deviation of CV scores for RandomForestRegressor on sample data: {cv_scores_rf_sample.std():.4f}")

overall_cv_rmse_rf_sample = np.abs(cv_scores_rf_sample.mean())
print(f"Overall Custom RMSE from cross-validation (RandomForestRegressor, Sample Data): {overall_cv_rmse_rf_sample:.4f}")

# Gather metrics for RandomForestRegressor
rfr_test_r2 = model_r2_score
rfr_test_mse = mse
rfr_test_custom_rmse = custom_rmse_score
rfr_sample_cv_rmse = overall_cv_rmse_rf_sample

# Gather metrics for GradientBoostingRegressor
gbr_test_r2 = model_r2_score_gbr
gbr_test_mse = mse_gbr
gbr_test_custom_rmse = custom_rmse_score_gbr
gbr_sample_cv_rmse = overall_cv_rmse_sample

# Create a dictionary for the comparison table
comparison_data = {
    'Metric': [
        'R-squared (Test Set)',
        'Mean Squared Error (Test Set)',
        'Custom RMSE (Train/Test)',
        'Custom RMSE (Sample CV)'
    ],
    'RandomForestRegressor': [
        f'{rfr_test_r2:.4f}',
        f'{rfr_test_mse:.4f}',
        f'{rfr_test_custom_rmse:.4f}',
        f'{rfr_sample_cv_rmse:.4f}'
    ],
    'GradientBoostingRegressor': [
        f'{gbr_test_r2:.4f}',
        f'{gbr_test_mse:.4f}',
        f'{gbr_test_custom_rmse:.4f}',
        f'{gbr_sample_cv_rmse:.4f}'
    ]
}

# Create the DataFrame
comparison_df = pd.DataFrame(comparison_data)

print("Model Performance Comparison:")
display(comparison_df)

"""**HYPERPARAMETER OPTIMIZATION**

GradientBoostingRegressor (Sample Data)
"""

#define hyper parameter grid
param_grid_gbr = {
    'n_estimators': [50, 100, 150],
    'learning_rate': [0.05, 0.1, 0.2],
    'max_depth': [3, 4, 5]
}

cv_gbr_grid = LeaveOneGroupOut() #instantiate LOGO CV

grid_search_gbr = GridSearchCV(
    estimator=gbr_model,
    param_grid=param_grid_gbr,
    cv=cv_gbr_grid,
    scoring=custom_scorer,
    n_jobs=-1,
    verbose=2
)

grid_search_gbr.fit(X_sample, y_sample, groups=groups_sample)

print("Best hyperparameters for GradientBoostingRegressor (Sample Data):")
print(grid_search_gbr.best_params_)

# The best_score_ is the negative of the custom RMSE, so take its absolute value
best_custom_rmse_gbr_grid = np.abs(grid_search_gbr.best_score_)
print(f"Best Custom RMSE for GradientBoostingRegressor (Sample Data): {best_custom_rmse_gbr_grid:.4f}")

"""For RandomForestRegressor (Sample Data)


"""

param_grid_rf = {
    'n_estimators': [50, 100, 150],
    'max_depth': [3, 5, 7],
    'min_samples_split': [2, 5, 10]
}

cv_rf_grid = LeaveOneGroupOut()

grid_search_rf = GridSearchCV(
    estimator=model,
    param_grid=param_grid_rf,
    cv=cv_rf_grid,
    scoring=custom_scorer,
    n_jobs=-1,
    verbose=2
)

grid_search_rf.fit(X_sample_rf, y_sample_rf, groups=groups_sample_rf)

print("Best hyperparameters for RandomForestRegressor (Sample Data):")
print(grid_search_rf.best_params_)

# The best_score_ is the negative of the custom RMSE, so take its absolute value
best_custom_rmse_rf_grid = np.abs(grid_search_rf.best_score_)
print(f"Best Custom RMSE for RandomForestRegressor (Sample Data): {best_custom_rmse_rf_grid:.4f}")

"""**FULL CV WITH TUNED MODELS**

GradientBoostingRegressor

Phase 2: Full CV using 500 demands
"""

#Instantiate the GBR model with the best hyperparameters on the sample model
tuned_gbr_model = GradientBoostingRegressor(learning_rate=0.2,
                                        max_depth=3,
                                        n_estimators=150,
                                        random_state=42)

cv_full = LeaveOneGroupOut()
cv_scores_full = cross_val_score(tuned_gbr_model, X, y, groups=groups, cv=cv_full, scoring=custom_scorer, n_jobs=-1)

print("Cross-validation scores (negative custom RMSE) on full data:")
print(cv_scores_full)
print(f"Mean CV custom RMSE on full data: {np.abs(cv_scores_full.mean()):.4f}")
print(f"Standard deviation of CV custom RMSE scores on full data: {cv_scores_full.std():.4f}")

"""RandomForestRegressor

Phase 2: Full CV using 500 demands
"""

tuned_rf_model = RandomForestRegressor(max_depth=3,
                                     min_samples_split=2,
                                     n_estimators=50,
                                     random_state=42)

cv_full_rf = LeaveOneGroupOut()
cv_scores_full_rf = cross_val_score(tuned_rf_model, X, y, groups=groups, cv=cv_full_rf, scoring=custom_scorer, n_jobs=-1)

print("Cross-validation scores (negative custom RMSE) on full data for RandomForestRegressor:")
print(cv_scores_full_rf)
print(f"Mean CV custom RMSE on full data for RandomForestRegressor: {np.abs(cv_scores_full_rf.mean()):.4f}")
print(f"Standard deviation of CV custom RMSE scores on full data for RandomForestRegressor: {cv_scores_full_rf.std():.4f}")



print("FINAL MODEL PERFORMANCE COMPARISON - ALL STAGES")


# Create comprehensive results table
results_summary = {
    'Stage': [
        'Baseline (P28 - Best Static)',
        'Train/Test Split (default)',
        'Sample CV (default, 20 demands)',
        'Sample CV (tuned, 20 demands)',
        'Full CV (tuned, 500 demands) - FINAL'
    ],
    'RandomForest': [
        '8.74 (baseline)',
        f'{rfr_test_custom_rmse:.2f}',
        f'{rfr_sample_cv_rmse:.2f}',
        f'{best_custom_rmse_rf_grid:.2f}',
        f'{np.abs(cv_scores_full_rf.mean()):.2f}'
    ],
    'GradientBoosting': [
        '8.74 (baseline)',
        f'{gbr_test_custom_rmse:.2f}',
        f'{gbr_sample_cv_rmse:.2f}',
        f'{best_custom_rmse_gbr_grid:.2f}',
        f'{np.abs(cv_scores_full.mean()):.2f}'
    ]
}

results_df = pd.DataFrame(results_summary)
print("\n")
display(results_df)

# Final improvements
rf_final_rmse = np.abs(cv_scores_full_rf.mean())
gb_final_rmse = np.abs(cv_scores_full.mean())
baseline_rmse = 8.74

rf_improvement = ((baseline_rmse - rf_final_rmse) / baseline_rmse) * 100
gb_improvement = ((baseline_rmse - gb_final_rmse) / baseline_rmse) * 100

print(f"\nFinal Performance vs Baseline:")
print(f"  RandomForest:       {rf_final_rmse:.2f} USD/MWh ({rf_improvement:.1f}% improvement)")
print(f"  GradientBoosting:   {gb_final_rmse:.2f} USD/MWh ({gb_improvement:.1f}% improvement)")
print(f"  Baseline (P28):     {baseline_rmse:.2f} USD/MWh")

